A small AI project that Seamlessly integrates object detection, text-to-speech synthesis, and speech recognition into a powerful interactive model. 
Here's a brief breakdown of what it does:

**Object Detection with YOLOv5:** This model uses the YOLOv5 framework to detect objects in real-time from a video feed.

**Text-to-Speech Integration:** Once an object is detected, the model uses a text-to-speech engine to describe the objext and its position.

**Fetch Object Details:** Leveraging Wikipedia's API, the model fetches and narrates iteresting facts about the detected objects.

**Speech Recognition:** it listenes for your commands, allowing you to interact with the model using natural language.

**OpenAI Question Answering:** You can ask questions about the detected objects, and the model will provide detailed answers using OpenAI's capabilites.

Here is a sample video of the Project in Action:




https://github.com/bhavayaggwal/Enhanced_obj_detection_with_speech_integration/assets/60818481/150a8b5e-49fb-4538-a9f6-ba19ddaa3d9a




I Hereby declare that this is not my original code and was copied and implemented for educational purposes only.
